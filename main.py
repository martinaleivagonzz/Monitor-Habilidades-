# -*- coding: utf-8 -*-
import os
import json
import pandas as pd
from datetime import datetime

# Importar mÃ³dulos del proyecto
from etl.extract import extract_data
from etl.transform import transform_data
from etl.load import load_data
from etl.classify import classify_skills_advanced, generar_matriz_competencias
from scoring import calcular_scoring_completo
from profile import menu_seleccionar_usuario, generar_recomendaciones_personalizadas, cargar_perfil_usuario

def main():
    """
    Pipeline ETL completo con sistema multi-usuario
    """
    print("ðŸš€ INICIANDO PIPELINE ETL - MONITOR DE HABILIDADES")
    print("=" * 60)
    
    # PASO 1: EXTRACCIÃ“N DE DATOS
    print("\nðŸ“¥ PASO 1: EXTRACCIÃ“N DE DATOS")
    print("-" * 30)
    
    try:
        df_raw = extract_data()
        if df_raw.empty:
            print("âŒ No se pudieron extraer datos. Saliendo...")
            return
        print(f"âœ… {len(df_raw)} ofertas extraÃ­das exitosamente")
    except Exception as e:
        print(f"âŒ Error en extracciÃ³n: {e}")
        return
    
    # PASO 2: TRANSFORMACIÃ“N Y EXTRACCIÃ“N DE SKILLS
    print("\nðŸ”„ PASO 2: TRANSFORMACIÃ“N DE DATOS")
    print("-" * 30)
    
    try:
        df_processed = transform_data(df_raw)
        if df_processed.empty:
            print("âŒ No se pudieron transformar datos. Saliendo...")
            return
        print(f"âœ… {len(df_processed)} ofertas transformadas con skills extraÃ­das")
    except Exception as e:
        print(f"âŒ Error en transformaciÃ³n: {e}")
        return
    
    # PASO 3: ANÃLISIS DE FRECUENCIA DE SKILLS
    print("\nðŸ“Š PASO 3: ANÃLISIS DE SKILLS")
    print("-" * 30)
    
    try:
        # Combinar todas las skills
        all_skills = []
        for _, row in df_processed.iterrows():
            all_skills.extend(row['skills_tecnicas'])
            all_skills.extend(row['skills_gestion'])
        
        # Contar frecuencia
        skills_count = pd.Series(all_skills).value_counts().reset_index()
        skills_count.columns = ['skill', 'frecuencia']
        
        # Calcular porcentaje
        total_ofertas = len(df_processed)
        skills_count['porcentaje'] = (skills_count['frecuencia'] / total_ofertas * 100).round(2)
        
        # Ordenar
        skills_count = skills_count.sort_values('frecuencia', ascending=False)
        
        print(f"âœ… {len(skills_count)} skills Ãºnicas identificadas")
        
    except Exception as e:
        print(f"âŒ Error en anÃ¡lisis de skills: {e}")
        return
    
    # PASO 4: CLASIFICACIÃ“N AVANZADA
    print("\nðŸŽ¯ PASO 4: CLASIFICACIÃ“N AVANZADA")
    print("-" * 30)
    
    try:
        clasificacion = classify_skills_advanced(skills_count)
        print("âœ… ClasificaciÃ³n avanzada completada")
    except Exception as e:
        print(f"âŒ Error en clasificaciÃ³n: {e}")
        clasificacion = {}
    
    # PASO 5: SELECCIÃ“N DE USUARIO
    print("\n" + "=" * 60)
    print("ðŸ‘¤ SISTEMA DE RECOMENDACIONES PERSONALIZADAS")
    print("=" * 60)
    
    usuario_id = menu_seleccionar_usuario()
    if not usuario_id:
        print("âŒ No se seleccionÃ³ usuario. Saliendo...")
        return
    
    # Cargar perfil del usuario
    perfil_usuario = cargar_perfil_usuario(usuario_id)
    if not perfil_usuario:
        print("âŒ No se pudo cargar el perfil del usuario. Saliendo...")
        return
    
    print(f"ðŸŽ¯ Usuario seleccionado: {perfil_usuario.get('nombre', usuario_id)}")
    
    # PASO 6: SCORING Y RUTAS DE APRENDIZAJE
    print("\nðŸ“ˆ PASO 6: SCORING PERSONALIZADO")
    print("-" * 30)
    
    try:
        scoring_result = calcular_scoring_completo(skills_count, usuario_id)
        
        if not scoring_result:
            print("âŒ No se pudo calcular scoring. Saliendo...")
            return
        
        print("âœ… Scoring y rutas de aprendizaje generados")
        
    except Exception as e:
        print(f"âŒ Error en scoring: {e}")
        return
    
    # PASO 7: GENERAR RECOMENDACIONES
    print("\nðŸ’¡ PASO 7: RECOMENDACIONES PERSONALIZADAS")
    print("-" * 30)
    
    try:
        recomendaciones = generar_recomendaciones_personalizadas(usuario_id, skills_count)
        
        if not recomendaciones:
            print("âŒ No se pudieron generar recomendaciones")
            return
        
        print("âœ… Recomendaciones personalizadas generadas")
        
    except Exception as e:
        print(f"âŒ Error en recomendaciones: {e}")
        return
    
    # PASO 8: GUARDAR RESULTADOS
    print("\nðŸ’¾ PASO 8: GUARDANDO RESULTADOS")
    print("-" * 30)
    
    try:
        # Asegurar que existe la carpeta processed
        os.makedirs("data/processed", exist_ok=True)
        
        # 1. Guardar datos procesados
        df_processed.to_csv("data/processed/jobs_processed.csv", index=False, encoding="utf-8-sig")
        print("âœ… jobs_processed.csv guardado")
        
        # 2. Guardar anÃ¡lisis de skills
        skills_count.to_csv("data/processed/skills_count.csv", index=False, encoding="utf-8-sig")
        print("âœ… skills_count.csv guardado")
        
        # 3. Guardar scoring
        scoring_result['scoring_df'].to_csv("data/processed/scoring_skills.csv", index=False, encoding="utf-8-sig")
        print("âœ… scoring_skills.csv guardado")
        
        # 4. Guardar matriz de competencias
        scoring_result['matriz_competencias'].to_csv("data/processed/matriz_competencias.csv", index=False, encoding="utf-8-sig")
        print("âœ… matriz_competencias.csv guardado")
        
        # 5. Guardar clasificaciÃ³n avanzada
        with open("data/processed/clasificacion_avanzada.json", "w", encoding="utf-8") as f:
            json.dump(scoring_result['clasificacion_avanzada'], f, indent=2, ensure_ascii=False)
        print("âœ… clasificacion_avanzada.json guardado")
        
        # 6. Guardar rutas de aprendizaje
        with open("data/processed/rutas_aprendizaje.json", "w", encoding="utf-8") as f:
            json.dump(scoring_result['rutas_aprendizaje'], f, indent=2, ensure_ascii=False)
        print("âœ… rutas_aprendizaje.json guardado")
        
        # 7. Guardar recomendaciones personalizadas
        archivo_recomendaciones = f"data/processed/recomendaciones_{usuario_id}.json"
        with open(archivo_recomendaciones, "w", encoding="utf-8") as f:
            json.dump(recomendaciones, f, indent=2, ensure_ascii=False)
        print(f"âœ… {archivo_recomendaciones} guardado")
        
        # 8. Guardar resumen ejecutivo
        resumen_ejecutivo = {
            "fecha_ejecucion": datetime.now().isoformat(),
            "usuario": usuario_id,
            "total_ofertas_analizadas": len(df_processed),
            "total_skills_identificadas": len(skills_count),
            "resumen_scoring": scoring_result['resumen'],
            "proxima_accion_recomendada": recomendaciones.get('proximo_paso', 'N/A'),
            "skills_criticas": recomendaciones.get('skills_criticas_para_aprender', [])
        }
        
        with open("data/processed/resumen_ejecutivo.json", "w", encoding="utf-8") as f:
            json.dump(resumen_ejecutivo, f, indent=2, ensure_ascii=False)
        print("âœ… resumen_ejecutivo.json guardado")
        
    except Exception as e:
        print(f"âŒ Error guardando resultados: {e}")
        return
    
    # PASO 9: MOSTRAR RESUMEN FINAL
    print("\nðŸŽ‰ PIPELINE COMPLETADO EXITOSAMENTE!")
    print("=" * 60)
    
    print(f"ðŸ“Š RESUMEN PARA {perfil_usuario.get('nombre', usuario_id)}:")
    print(f"   â€¢ ðŸ“ˆ Ofertas analizadas: {len(df_processed)}")
    print(f"   â€¢ ðŸŽ¯ Skills identificadas: {len(skills_count)}")
    print(f"   â€¢ ðŸ’ª Skills que ya tienes: {scoring_result['resumen']['cobertura_actual']}")
    print(f"   â€¢ ðŸ“š Skills para aprender: {scoring_result['resumen']['skills_para_aprender_urgente']}")
    print(f"   â€¢ ðŸš€ PrÃ³xima skill recomendada: {scoring_result['resumen']['proxima_skill_recomendada']}")
    print(f"   â€¢ ðŸ’¡ PrÃ³ximo paso: {recomendaciones.get('proximo_paso', 'N/A')}")
    
    if recomendaciones.get('skills_criticas_para_aprender'):
        print(f"\nðŸ”´ SKILLS CRÃTICAS PARA APRENDER:")
        for i, skill in enumerate(recomendaciones['skills_criticas_para_aprender'][:3], 1):
            print(f"   {i}. {skill}")
    
    if scoring_result['rutas_aprendizaje']:
        print(f"\nðŸ—ºï¸  RUTAS DE APRENDIZAJE DISPONIBLES:")
        for ruta in scoring_result['rutas_aprendizaje'][:2]:
            print(f"   â€¢ {ruta['nombre']} ({ruta['timeline']})")
    
    print(f"\nðŸ’¾ Resultados guardados en: data/processed/")
    print(f"ðŸ“ Archivos generados:")
    print(f"   - jobs_processed.csv (ofertas procesadas)")
    print(f"   - skills_count.csv (frecuencia skills)")
    print(f"   - scoring_skills.csv (scoring personalizado)")
    print(f"   - recomendaciones_{usuario_id}.json (recomendaciones)")
    print(f"   - rutas_aprendizaje.json (rutas de aprendizaje)")
    
    print(f"\nðŸŽ¯ PrÃ³ximos pasos:")
    print(f"   1. Revisar recomendaciones en data/processed/recomendaciones_{usuario_id}.json")
    print(f"   2. Ejecutar dashboard.py para visualizaciÃ³n interactiva")
    print(f"   3. Actualizar tu perfil con nuevas skills adquiridas")

def ejecutar_modo_rapido():
    """
    Modo rÃ¡pido para testing sin interacciÃ³n de usuario
    """
    print("âš¡ MODO RÃPIDO - EJECUCIÃ“N AUTOMÃTICA")
    
    try:
        # ExtracciÃ³n
        df_raw = extract_data()
        if df_raw.empty:
            print("âŒ No hay datos para procesar")
            return
        
        # TransformaciÃ³n
        df_processed = transform_data(df_raw)
        
        # AnÃ¡lisis bÃ¡sico
        all_skills = []
        for _, row in df_processed.iterrows():
            all_skills.extend(row['skills_tecnicas'])
            all_skills.extend(row['skills_gestion'])
        
        skills_count = pd.Series(all_skills).value_counts().reset_index()
        skills_count.columns = ['skill', 'frecuencia']
        skills_count['porcentaje'] = (skills_count['frecuencia'] / len(df_processed) * 100).round(2)
        skills_count = skills_count.sort_values('frecuencia', ascending=False)
        
        # Guardar resultados bÃ¡sicos
        os.makedirs("data/processed", exist_ok=True)
        df_processed.to_csv("data/processed/jobs_processed.csv", index=False, encoding="utf-8-sig")
        skills_count.to_csv("data/processed/skills_count.csv", index=False, encoding="utf-8-sig")
        
        print(f"âœ… Modo rÃ¡pido completado:")
        print(f"   â€¢ {len(df_processed)} ofertas procesadas")
        print(f"   â€¢ {len(skills_count)} skills identificadas")
        print(f"   â€¢ Archivos guardados en data/processed/")
        
    except Exception as e:
        print(f"âŒ Error en modo rÃ¡pido: {e}")

if __name__ == "__main__":
    import sys
    
    # Verificar argumentos para modo rÃ¡pido
    if len(sys.argv) > 1 and sys.argv[1] == "--rapido":
        ejecutar_modo_rapido()
    else:
        main()